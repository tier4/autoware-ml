# @package _global_
defaults:
  - /defaults/default_runtime
  - _self_

datamodule:
  stack_keys: [fused_img, gt_calibration_status]
  train_dataloader_cfg:
    batch_size: 8
    persistent_workers: true
    num_workers: 4
    shuffle: true
  val_dataloader_cfg:
    batch_size: 8
    persistent_workers: true
    num_workers: 4
  test_dataloader_cfg:
    batch_size: 8
    persistent_workers: true
    num_workers: 4
  predict_dataloader_cfg:
    batch_size: 1
    persistent_workers: true
    num_workers: 1
  train_transforms:
    pipeline:
      - _target_: autoware_ml.transforms.lidar.CropBoxInner
        crop_box: [-1.53, -1.15, -0.1, 5.72, 1.15, 3.1]
      - _target_: autoware_ml.transforms.camera.UndistortImage
        alpha: 0.0
      - _target_: autoware_ml.transforms.camera_lidar.CalibrationMisalignment
        p: 0.5
        activate_roll: true
        activate_pitch: true
        activate_yaw: true
        activate_x: true
        activate_y: true
        activate_z: true
        min_roll_neg: 4.2
        max_roll_neg: 8.4
        min_roll_pos: 4.2
        max_roll_pos: 8.4
        min_pitch_neg: 0.2
        max_pitch_neg: 0.4
        min_pitch_pos: 0.2
        max_pitch_pos: 0.4
        min_yaw_neg: 0.2
        max_yaw_neg: 0.4
        min_yaw_pos: 0.2
        max_yaw_pos: 0.4
        min_x_neg: 0.54
        max_x_neg: 1.08
        min_x_pos: 0.24
        max_x_pos: 0.48
        min_y_neg: 0.22
        max_y_neg: 0.44
        min_y_pos: 0.22
        max_y_pos: 0.44
        min_z_neg: 0.12
        max_z_neg: 0.24
        min_z_pos: 0.06
        max_z_pos: 0.12
      - _target_: autoware_ml.transforms.camera.CropAndScale
        p: 0.2
        crop_ratio: 0.8
      - _target_: autoware_ml.transforms.camera_lidar.Affine
        p: 0.2
        max_distortion: 0.05
      - _target_: autoware_ml.transforms.image.PhotometricDistortion
        p: 0.2
        brightness: 0.1
        contrast: 0.1
        saturation: 0.1
        hue: 0.05
      - _target_: autoware_ml.transforms.camera_lidar.LidarCameraFusion
        max_depth: 128.0
        dilation_size: 1
        ego_box: [-1.53, -1.15, -0.1, 5.72, 1.15, 3.1]
      - _target_: autoware_ml.transforms.camera_lidar.SaveFusionPreview
        p: 0.00001
        out_dir: ${hydra:run.dir}/previews
        max_depth: 128.0
        alpha: 1.0
        depth_colormap: jet
        intensity_colormap: turbo
      - _target_: autoware_ml.transforms.common.PermuteAxes
        input_keys: [fused_img]
        axes: [2, 0, 1]
  val_transforms:
    pipeline:
      - _target_: autoware_ml.transforms.lidar.CropBoxInner
        crop_box: [-1.53, -1.15, -0.1, 5.72, 1.15, 3.1]
      - _target_: autoware_ml.transforms.camera.UndistortImage
        alpha: 0.0
      - _target_: autoware_ml.transforms.camera_lidar.CalibrationMisalignment
        p: 0.5
        activate_roll: true
        activate_pitch: true
        activate_yaw: true
        activate_x: true
        activate_y: true
        activate_z: true
        min_roll_neg: 4.2
        max_roll_neg: 8.4
        min_roll_pos: 4.2
        max_roll_pos: 8.4
        min_pitch_neg: 0.2
        max_pitch_neg: 0.4
        min_pitch_pos: 0.2
        max_pitch_pos: 0.4
        min_yaw_neg: 0.2
        max_yaw_neg: 0.4
        min_yaw_pos: 0.2
        max_yaw_pos: 0.4
        min_x_neg: 0.54
        max_x_neg: 1.08
        min_x_pos: 0.24
        max_x_pos: 0.48
        min_y_neg: 0.22
        max_y_neg: 0.44
        min_y_pos: 0.22
        max_y_pos: 0.44
        min_z_neg: 0.12
        max_z_neg: 0.24
        min_z_pos: 0.06
        max_z_pos: 0.12
      - _target_: autoware_ml.transforms.camera_lidar.LidarCameraFusion
        max_depth: 128.0
        dilation_size: 1
        ego_box: [-1.53, -1.15, -0.1, 5.72, 1.15, 3.1]
      - _target_: autoware_ml.transforms.common.PermuteAxes
        input_keys: [fused_img]
        axes: [2, 0, 1]
  test_transforms:
    pipeline:
      - _target_: autoware_ml.transforms.lidar.CropBoxInner
        crop_box: [-1.53, -1.15, -0.1, 5.72, 1.15, 3.1]
      - _target_: autoware_ml.transforms.camera.UndistortImage
        alpha: 0.0
      - _target_: autoware_ml.transforms.camera_lidar.CalibrationMisalignment
        p: 0.5
        activate_roll: true
        activate_pitch: true
        activate_yaw: true
        activate_x: true
        activate_y: true
        activate_z: true
        min_roll_neg: 4.2
        max_roll_neg: 8.4
        min_roll_pos: 4.2
        max_roll_pos: 8.4
        min_pitch_neg: 0.2
        max_pitch_neg: 0.4
        min_pitch_pos: 0.2
        max_pitch_pos: 0.4
        min_yaw_neg: 0.2
        max_yaw_neg: 0.4
        min_yaw_pos: 0.2
        max_yaw_pos: 0.4
        min_x_neg: 0.54
        max_x_neg: 1.08
        min_x_pos: 0.24
        max_x_pos: 0.48
        min_y_neg: 0.22
        max_y_neg: 0.44
        min_y_pos: 0.22
        max_y_pos: 0.44
        min_z_neg: 0.12
        max_z_neg: 0.24
        min_z_pos: 0.06
        max_z_pos: 0.12
      - _target_: autoware_ml.transforms.camera_lidar.LidarCameraFusion
        max_depth: 128.0
        dilation_size: 1
        ego_box: [-1.53, -1.15, -0.1, 5.72, 1.15, 3.1]
      - _target_: autoware_ml.transforms.common.PermuteAxes
        input_keys: [fused_img]
        axes: [2, 0, 1]
  predict_transforms:
    pipeline:
      - _target_: autoware_ml.transforms.lidar.CropBoxInner
        crop_box: [-1.53, -1.15, -0.1, 5.72, 1.15, 3.1]
      - _target_: autoware_ml.transforms.camera.UndistortImage
        alpha: 0.0
      - _target_: autoware_ml.transforms.camera_lidar.CalibrationMisalignment
        p: 0.5
        activate_roll: true
        activate_pitch: true
        activate_yaw: true
        activate_x: true
        activate_y: true
        activate_z: true
        min_roll_neg: 4.2
        max_roll_neg: 8.4
        min_roll_pos: 4.2
        max_roll_pos: 8.4
        min_pitch_neg: 0.2
        max_pitch_neg: 0.4
        min_pitch_pos: 0.2
        max_pitch_pos: 0.4
        min_yaw_neg: 0.2
        max_yaw_neg: 0.4
        min_yaw_pos: 0.2
        max_yaw_pos: 0.4
        min_x_neg: 0.54
        max_x_neg: 1.08
        min_x_pos: 0.24
        max_x_pos: 0.48
        min_y_neg: 0.22
        max_y_neg: 0.44
        min_y_pos: 0.22
        max_y_pos: 0.44
        min_z_neg: 0.12
        max_z_neg: 0.24
        min_z_pos: 0.06
        max_z_pos: 0.12
      - _target_: autoware_ml.transforms.camera_lidar.LidarCameraFusion
        max_depth: 128.0
        dilation_size: 1
        ego_box: [-1.53, -1.15, -0.1, 5.72, 1.15, 3.1]
      - _target_: autoware_ml.transforms.common.PermuteAxes
        input_keys: [fused_img]
        axes: [2, 0, 1]
  data_preprocessing:
    pipeline:

model:
  _target_: autoware_ml.models.calibration_status.CalibrationStatusClassifier
  backbone:
    _target_: autoware_ml.models.common.backbones.resnet.ResNet18
    in_channels: 5
  neck:
    _target_: autoware_ml.models.common.necks.global_average_pooling.GlobalAveragePooling
  head:
    _target_: autoware_ml.models.common.heads.linear_cls_head.LinearClsHead
    num_classes: 2
    in_channels: 512
    loss:
      _target_: torch.nn.CrossEntropyLoss
    topk: [1]
    cal_acc: true
  optimizer:
    _target_: torch.optim.AdamW
    lr: 0.001
    weight_decay: 0.01
    betas: [0.9, 0.999]
    eps: 1e-8
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 20
    eta_min: 1e-8
    last_epoch: -1

trainer:
  max_epochs: 30
  gradient_clip_val: 10.0
  gradient_clip_algorithm: norm

deploy:
  onnx:
    dynamic_shapes:
      fused_img: { 2: height, 3: width }
    input_names: [input]
    output_names: [output]
  tensorrt:
    input_shapes:
      input:
        min_shape: [1, 5, 1080, 1920]
        opt_shape: [1, 5, 1860, 2880]
        max_shape: [1, 5, 2160, 3840]
